# -*- coding: utf-8 -*-
"""AIMm.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11A_CZo3x1XYIPhecQ2_gsWYftUTYqOcu

# **AIMm**
---
## Artificial Intelligence for Matchmaking  

AIMm √® un sistema di matchmaking basato sull'intelligenza artificiale che mira a bilanciare le lobby di gioco in modo ottimale.  
Utilizzando tecniche di clustering, assicura che i giocatori affrontino avversari con abilit√† simili ma senza eccessiva uniformit√†.  
In questo modo, si garantisce un'esperienza dinamica e divertente sia per i principianti che per i giocatori pi√π esperti.

# üì¶ **Importazione delle Librerie**  

Per implementare il sistema di matchmaking basato su AI, abbiamo deciso di importare le seguenti librerie.  
Queste saranno utilizzate sia per la **visualizzazione dei dati** che per l'**implementazione degli algoritmi** necessari.
"""

import pandas as pd
import numpy as np
from google.colab import data_table
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
from sklearn.neighbors import NearestNeighbors
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from mpl_toolkits.mplot3d import Axes3D
from IPython.display import display
from pandas.plotting import table
from IPython.display import Image, display
from tabulate import tabulate
import random


data_table.enable_dataframe_formatter()
data_table.DataTable.max_columns = 25

"""# üìä **Visualizzazione del Dataset**  

Qui presentiamo il dataset preso in considerazione per il sistema di matchmaking.
Il dataset si basa  
Durante la fase di **Data Understanding**, possiamo osservare le seguenti caratteristiche:  

## üîπ **Caratteristiche Principali del Dataset**  
- **name**: Nome del giocatore.  
- **wins**: Numero di partite vinte dal giocatore.  
- **kills**: Numero totale di uccisioni effettuate dal giocatore in tutte le partite.  
- **kdRatio**: Rapporto uccisioni/morti. Se un giocatore ha 10 uccisioni e 5 morti, il suo KD ratio √® uguale a 2. Un KD ratio di 1 significa che il giocatore √® stato ucciso lo stesso numero di volte delle sue uccisioni.  
- **killstreak**: Record del numero di nemici uccisi consecutivamente senza morire.  
- **level**: Livello del giocatore (il suo grado).  
- **losses**: Numero totale di sconfitte del giocatore.  
- **prestige**: √à una modalit√† opzionale che i giocatori possono scegliere dopo aver raggiunto il livello 55 e aver massimizzato il loro livello.  
- **hits**: Numero di volte che il giocatore ha danneggiato un altro giocatore.  
- **timePlayed**: Tempo totale (in ore) trascorso dal giocatore a giocare a Call of Duty.  
- **headshots**: Numero di colpi alla testa inflitti dal giocatore.  
- **averageTime**: Tempo medio di gioco per partita.  
- **gamesPlayed**: Numero totale di partite giocate dal giocatore in modalit√† multiplayer.  
- **assists**: Numero di volte in cui il giocatore ha danneggiato un nemico, ma √® stato un compagno di squadra a completare l'uccisione.  
- **misses**: Numero di colpi mancati dal giocatore.  
- **xp**: Punti Esperienza (XP), che sono un valore numerico esclusivo della modalit√† multiplayer e determinano il livello e i progressi del giocatore nel gioco.  
- **scorePerMinute**: Misura di quanti punti il giocatore guadagna per unit√† di tempo.  
- **shots**: Numero di colpi sparati dal giocatore.  
- **deaths**: Numero di volte in cui il giocatore √® stato ucciso nel gioco.
"""

dataset = pd.read_csv("cod.csv")

dataset

"""# üîç **Ricerca dei Dati NaN nel Dataset**

Per verificare se ci sono dati mancanti nel nostro dataset, possiamo eseguire una ricerca di valori **NaN** (Not a Number).  
Questo √® un passaggio importante per garantire che i dati siano completi e pronti per l'analisi.
"""

nan_mask = dataset.isna()
nan_count = nan_mask.sum()

nan_count

"""# üìä **Descrizione del Dataset con `.describe()`**

Il comando `.describe()` fornisce una panoramica statistica del dataset.  
Mostra informazioni come la **media**, il **minimo**, il **massimo**, i **quartili** e altre metriche descrittive per ogni colonna numerica.  
√à utile per comprendere la distribuzione dei dati e identificare eventuali anomalie.
"""

dataset.describe()

"""# üî¢ **Ordinamento della Tabella per una Visualizzazione Migliore**

Per visualizzare i dati in modo pi√π comodo, possiamo ordinare il dataset in base a una o pi√π colonne.  
Ad esempio, possiamo ordinare per la colonna "wins" per vedere i giocatori con il maggior numero di vittorie in cima.

# ‚ûï **Aggiunta di Nuove Colonne al Dataset**

Abbiamo deciso di aggiungere alcune nuove colonne al dataset per calcolare e memorizzare valori aggiuntivi.  
Le colonne vengono inserite in posizioni specifiche utilizzando il metodo `insert()`.

"""

pos = dataset.columns.get_loc("kills")
col = dataset.pop("deaths")
dataset.insert(pos + 1, "deaths", col)

pos = dataset.columns.get_loc("wins")
col = dataset.pop("losses")
dataset.insert(pos + 1, "losses", col)

pos = dataset.columns.get_loc("losses")
col = dataset.pop("gamesPlayed")
dataset.insert(pos + 1, "wlRatio",np.nan)
dataset.insert(pos + 2, "gamesPlayed", col)

pos = dataset.columns.get_loc("prestige")
col = dataset.pop("shots")
dataset.insert(pos + 1, "shots", col)

pos = dataset.columns.get_loc("hits")
col = dataset.pop("misses")
dataset.insert(pos + 1, "misses", col)
col = dataset.pop("headshots")
dataset.insert(pos + 2, "headshots", col)
dataset.insert(pos + 3, "precisionHead", np.nan)
dataset.insert(pos + 4, "precisionAim", np.nan)
col = dataset.pop("timePlayed")
dataset.insert(pos + 5, "timePlayed", col)

dataset

"""# üö´ **Colonne Non Valutate e Divisione del Nickname**

Per raggiungere il nostro obiettivo, abbiamo deciso di **non valutare** le seguenti colonne.  
Inoltre, abbiamo **diviso** il **Nickname** in due colonne separate: **Gamertag** e **Tag**.

### üìå **Colonne Non Valutate**  
- `averageTime`
- `assists`
- `xp`
- `scorePerMinute`

### üìå **Divisione del Nickname**
Abbiamo separato il **Nickname** in due nuove colonne:
- **Gamertag**: La parte principale del nome del giocatore.  
- **Tag**: Il tag identificativo (ad esempio, numerico o simbolico).
"""

dataset.drop(['averageTime'], axis = 1, inplace = True)
dataset.drop(['assists'], axis = 1, inplace = True)
dataset.drop(['xp'], axis = 1, inplace = True)
dataset.drop(['scorePerMinute'], axis = 1, inplace = True)

dataset['gamertag'] = dataset['name'].apply(lambda x: x.split('#')[0] if '#' in x else x)
dataset['tag'] = dataset['name'].apply(lambda x: x.split('#')[1] if '#' in x else '')


dataset

dataset['gamertag']

dataset['tag']

"""## Abbiamo deciso di aggiungere la colonna **Gamertag** al dataset al posto della colonna **name**, che √® stata separata in due parti (Gamertag e Tag)."""

dataset.drop(['name'], axis = 1, inplace = True)
col = dataset.pop("gamertag")
dataset.insert(0, "gamertag", col)
dataset.drop(['tag'], axis = 1, inplace = True)
dataset

"""# üìù **Riempimento delle Nuove Colonne**

Una volta aggiunte le nuove colonne, √® necessario riempirle con i valori corretti. Ad esempio, possiamo calcolare il **wlRatio**, la **precisionHead** e la **precisionAim** in base ad altre informazioni presenti nel dataset
"""

dataset["wlRatio"] = dataset["wins"] / dataset["losses"]
dataset["precisionHead"] = dataset["headshots"] / dataset["hits"]
dataset["precisionAim"] = dataset["hits"] / dataset["shots"]

dataset

"""# ‚ö†Ô∏è **Correzione dei Valori NaN nelle Nuove Colonne**

I valori **NaN** possono essere generati durante le operazioni matematiche, come divisioni per zero o altre incoerenze nei dati.  
Per evitare problemi, possiamo sostituire questi valori **NaN** con valori appropriati, come **0** o la **media** della colonna.
"""

dataset["wlRatio"] = dataset["wlRatio"].round(2)
dataset["kdRatio"] = dataset["kdRatio"].round(2)
dataset["precisionHead"] = dataset["precisionHead"].round(2)
dataset["precisionAim"] = dataset["precisionAim"].round(2)

dataset["wlRatio"] = dataset["wlRatio"].fillna(0)
dataset["precisionHead"] = dataset["precisionHead"].fillna(0)
dataset["precisionAim"] = dataset["precisionAim"].fillna(0)

dataset

"""# üîß **Correzione dei Valori Infinity**

Durante i calcoli, potrebbero verificarsi valori **Infinity** (positivi o negativi) dovuti a divisioni per 0 o ad altre operazioni matematiche.  
Per correggere questi valori, possiamo sostituire i valori **Infinity** con **NaN** o un altro valore predefinito.
"""

infinity_rows = dataset[dataset.isin([float('inf'), float('-inf')]).any(axis=1)]
infinity_rows

dataset["wlRatio"] = np.where(dataset["losses"] == 0, dataset["wins"], dataset["wins"] / dataset["losses"])

infinity_rows = dataset[dataset.isin([float('inf'), float('-inf')]).any(axis=1)]
infinity_rows

"""# üîß **Rimozione delle Righe Anomale e Applicazione del Rounding**

Per pulire ulteriormente il dataset, rimuoviamo alcune righe che sono considerate anomale in base a determinati criteri.  
Inoltre, applichiamo un **rounding** permanente alla colonna **wlRatio**.
"""

# Rimuovi righe con shots < headshots
dataset = dataset[dataset["shots"] >= dataset["headshots"]]

# Rimuovi righe con shots = 0 e level > 1
dataset = dataset[~((dataset["shots"] == 0) & (dataset["level"] > 1))]

# Applicare il rounding PERMANENTE dopo il filtraggio
dataset["wlRatio"] = dataset["wlRatio"].round(2)

dataset

"""# üîß **Gestione della Divisione per 0 e Identificazione dei Valori Infinity**

Per evitare divisioni per **0** e gestire i valori **Infinity**, abbiamo utilizzato `np.where` per calcolare correttamente la colonna **wlRatio**. Inoltre, identifichiamo le righe con valori **Infinity** per ulteriori correzioni.
"""

dataset["wlRatio"] = np.where(dataset["losses"] == 0, dataset["wins"], dataset["wins"] / dataset["losses"])

infinity_rows = dataset[dataset.isin([float('inf'), float('-inf')]).any(axis=1)]
infinity_rows

"""# üîß **Rimozione delle Righe Anomale e Gestione dei Valori Infinity**

Per assicurarsi che il dataset sia pulito, rimuoviamo le righe in cui il numero di **headshots** supera il numero di **shots** meno i **misses**.  
Successivamente, identifichiamo le righe che contengono valori **Infinity** (sia positivi che negativi).
"""

dataset = dataset[dataset["headshots"] <= (dataset["shots"] - dataset["misses"])]

infinity_rows = dataset[dataset.isin([float('inf'), float('-inf')]).any(axis=1)]


infinity_rows

dataset["wlRatio"] = dataset["wlRatio"].round(2)
dataset

"""# üîß **Filtraggio delle Righe Anomale e Applicazione del Rounding**

Per migliorare la qualit√† del dataset, rimuoviamo le righe che presentano anomalie in base a determinate condizioni.  
Dopo aver applicato il filtraggio, eseguiamo un **rounding** della colonna **wlRatio**.
"""

dataset = dataset[~((dataset["prestige"] > 0) & (dataset["gamesPlayed"] < 1))]

dataset = dataset[~((dataset["kills"] > 0) | (dataset["deaths"] > 0)) | (dataset["gamesPlayed"] > 0)]

dataset["wlRatio"] = dataset["wlRatio"].round(2)
dataset

dataset

"""# üîß **Modifica dei Valori di Prestigio e Regolazione del Livello**

Per il prestigio abbiamo deciso di ispirarci al suo meccanismo nella pi√π recente iterazione di Call of Duty: "Call of Duty Black Ops 6". Il prestigio √® un meccanismo in cui  i giocatori possono scegliere, dopo aver raggiunto il livello 55, di resettare i loro progressi per ricevere ricompense. In Black Ops 6 abbiamo 10 prestigi pi√π l'11 prestigio chiamato **"Maestro Prestigio"**. Per garantire che i valori di **prestigio** non superino 11, impostiamo quelli maggiori di 11 a 11. Inoltre, calcoliamo il prestigio guadagnato in base al livello del giocatore, aggiornando sia il livello che il prestigio.
"""

# Modifica i valori di prestigio superiori a 10, impostandoli a 11
dataset['prestige'] = dataset['prestige'].apply(lambda x: 11 if x > 10 else x)

def adjust_level_and_prestige(row):
    if row['prestige'] < 11 and row['level'] > 55:
        # Calcolare il numero di prestigio guadagnato
        prestige_gained = int(row['level'] // 55) - 1

        # Nuovo livello: livello attuale meno 55 per ogni prestigio guadagnato
        new_level = row['level'] - (prestige_gained * 55)

        # Nuovo prestigio: prestigio attuale pi√π quello guadagnato
        new_prestige = row['prestige'] + prestige_gained

        return pd.Series([new_level, new_prestige])
    else:
        return pd.Series([row['level'], row['prestige']])

# Applicare la funzione al dataset
dataset[['level', 'prestige']] = dataset.apply(adjust_level_and_prestige, axis=1)
dataset["wlRatio"] = dataset["wlRatio"].round(2)

dataset

"""# üîß **Calcolo delle Colonne 'gamesPlayed' e 'shots'**

Correggiamo il numero totale di **gamesPlayed** e **shots**, sommiamo i valori delle colonne **wins** + **losses** e **hits** + **misses**, rispettivamente.
"""

dataset["gamesPlayed"] = dataset["wins"] + dataset["losses"]
dataset["shots"] = dataset["hits"] + dataset["misses"]

dataset

"""# üîß **Filtraggio delle Righe e Regolazione della Colonna 'killstreak'**

Per pulire il dataset, rimuoviamo le righe in cui un giocatore ha fatto **kills** senza aver mai **hits**. Inoltre, limitiamo il valore della colonna **killstreak** a 30, per evitare valori troppo alti e prendiamo in considerazione il numero di uccisioni consecutive senza morire per l'ultima ricompensa (killstreak) ottenibile .

"""

dataset = dataset[~((dataset['kills'] > 0) & (dataset['hits'] == 0))]
dataset = dataset.assign(killstreak=dataset['killstreak'].where(dataset['killstreak'] <= 30, 30))



dataset["wlRatio"] = dataset["wlRatio"].round(2)
dataset

dataset.describe()

"""# üîß **Creazione della Colonna 'totalLevelAccount' e Rimozione di 'level' e 'prestige'**

Per ottenere il livello totale dell'account, creiamo una nuova colonna **totalLevelAccount** combinando il livello e il prestigio. Successivamente, rimuoviamo le colonne **level** e **prestige** e spostiamo la colonna **totalLevelAccount** nella posizione corretta.
"""

dataset['totalLevelAccount'] = dataset['level'] + 55 * dataset['prestige']
dataset.drop(['level'], axis = 1, inplace = True)
dataset.drop(['prestige'], axis = 1, inplace = True)

pos = dataset.columns.get_loc("killstreak")
col = dataset.pop("totalLevelAccount")
dataset.insert(pos + 1, "totalLevelAccount", col)

dataset

"""# üîß **Filtraggio dei Valori Anomali in 'wlRatio'**

Per evitare valori anomali, rimuoviamo le righe in cui il valore della colonna **wlRatio** √® maggiore di 100.
"""

dataset = dataset[~(dataset["wlRatio"] > 100)]
dataset

"""# üîß **Selezione delle Feature**

Per la selezione delle feature, estraiamo un sottoinsieme del dataset, scegliendo le colonne che riteniamo pi√π rilevanti per l'analisi e il modello. In questo caso, selezioniamo le colonne **[3, 4, 7, 8, 9, 14, 15, 16]**
<br>
Features = **['wlRatio', 'gamesPlayed', 'kdRatio', 'killstreak', 'totalLevelAccount', 'precisionHead', 'precisionAim', 'timePlayed']**
"""

X = dataset.iloc[:, [3, 4, 7, 8, 9, 14, 15, 16]]
X.head()

"""# üîß **Creazione dell'Array di Pesi e Applicazione del K-Means Clustering**

In questo passaggio, utilizziamo il **K-Means Clustering** per raggruppare i dati in cluster, dopo aver attribuito dei pesi alle diverse feature. La selezione dei pesi si basa sulla divisione **70-30** tra due gruppi di caratteristiche: alcune features avranno un peso maggiore (70%) rispetto ad altre (30%). Questo aiuta a dare pi√π importanza ad alcune variabili rispetto ad altre, influenzando cos√¨ la formazione dei cluster.

### üìå **Passaggi del Codice:**
1. **Creazione dell'array di pesi:**
   Viene definito un array di pesi in cui ad alcune colonne del dataset viene dato un peso maggiore (2.0) e ad altre un peso minore (1.0). Le colonne con un peso maggiore sono considerate pi√π rilevanti per l'analisi, mentre le altre vengono ponderate di meno.

2. **Applicazione dei pesi:**
   I pesi vengono applicati moltiplicando le feature del dataset per i valori definiti nell'array di pesi. Questo modifica l'importanza relativa delle diverse caratteristiche nel clustering.

3. **Normalizzazione dei dati:**
   I dati vengono normalizzati utilizzando **StandardScaler**. Questo √® un passaggio cruciale, perch√© le diverse scale delle feature potrebbero influenzare il risultato del clustering. La normalizzazione rende tutte le feature comparabili, portandole su una scala comune.

4. **Metodo Elbow:**
   Il metodo **Elbow** viene utilizzato per determinare il numero ottimale di cluster. In pratica, calcoliamo l'inertia (la somma degli errori quadrati) per vari numeri di cluster (da 1 a 10) e tracciamo un grafico. L'idea √® di trovare il punto in cui l'inertia smette di diminuire drasticamente, che indica il numero migliore di cluster da scegliere.

### üìå **Cosa Fa Il Metodo Elbow:**
- **Inertia** misura quanto i punti in un cluster siano lontani dal centroide del cluster stesso. Un valore pi√π basso di inertia indica un miglior raggruppamento.
- Tracciando l'inertia in funzione del numero di cluster, possiamo identificare un "gomito" nel grafico, che ci mostra il punto ideale in cui aggiungere nuovi cluster non migliora significativamente il risultato.

### üìå **Obiettivo:**
L'obiettivo finale √® trovare il numero di cluster che meglio rappresenta i dati, considerando l'importanza relativa delle feature, e ottenere una divisione che consenta una migliore analisi dei gruppi di dati.
"""

# Creiamo un array di pesi basato sulla divisione 70-30

weights = np.array([
    2.0,  # Feature 3  -> Gruppo 70%
    1.0,  # Feature 4  -> Gruppo 30%
    2.0,  # Feature 7  -> Gruppo 70%
    2.0,  # Feature 8  -> Gruppo 70%
    1.0,  # Feature 9  -> Gruppo 30%
    2.0,  # Feature 14 -> Gruppo 70%
    2.0,  # Feature 15 -> Gruppo 70%
    1.0   # Feature 16 -> Gruppo 30%
])


# Applichiamo i pesi moltiplicando le feature
X_weighted = X * weights

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X_weighted) #

wcss = []
max_clusters = 10

for i in range(1, max_clusters + 1):
    kmeans = KMeans(n_clusters=i)
    kmeans.fit(X_scaled)
    wcss.append(kmeans.inertia_)

# Grafico Elbow
plt.figure(figsize=(8,6))
plt.plot(range(1, 11), wcss, marker='o')
plt.title("Elbow Method - Ottimizzazione numero di cluster")
plt.xlabel("Numero di cluster")
plt.ylabel("Somma degli errori quadrati (SSE)")
plt.show()

"""# üîç **Clusterizzazione e Visualizzazione dei Dati con K-Means e PCA**

In questa fase, applichiamo il **K-Means Clustering** per raggruppare i dati in 6 cluster, scelto in base al metodo Elbow, e riduciamo la dimensionalit√† dei dati a 2 componenti per visualizzare i cluster in un grafico 2D. Successivamente, il clustering viene visualizzato in uno scatter plot, dove i punti sono colorati in base al cluster di appartenenza.
"""

# Imposta il numero di cluster scelto (6)
optimal_k = 6
kmeans = KMeans(n_clusters=optimal_k, random_state=42)
cluster_labels = kmeans.fit_predict(X_scaled)

# Aggiungi le etichette dei cluster al dataset originale
dataset['Cluster'] = cluster_labels

# Riduci le 8 dimensioni a 2 componenti
pca = PCA(n_components=2)
principal_components = pca.fit_transform(X_scaled)

# Crea lo scatter plot, colorando i punti in base ai cluster
plt.figure(figsize=(8, 6))
plt.scatter(principal_components[:, 0], principal_components[:, 1], c=dataset['Cluster'], cmap='viridis', alpha=0.6)
plt.xlabel('Componente Principale 1')
plt.ylabel('Componente Principale 2')
plt.title('Visualizzazione dei Cluster (PCA)')
plt.colorbar(label='Cluster')
plt.show()

"""# üîç **Visualizzazione dei Cluster in 3D con PCA**

In questa fase, riduciamo ulteriormente le dimensioni del nostro dataset a **3 componenti principali** tramite **PCA (Principal Component Analysis)**, per ottenere una rappresentazione in 3D. Successivamente, visualizziamo i cluster utilizzando un grafico 3D, colorando i punti in base ai loro cluster di appartenenza.
"""

# Riduci le 8 dimensioni a 3 componenti
pca = PCA(n_components=3)
principal_components = pca.fit_transform(X_scaled)

# Crea la figura e il grafico 3D
fig = plt.figure(figsize=(10, 8))
ax = fig.add_subplot(111, projection='3d')

# Scatter plot dei cluster in 3D
scatter = ax.scatter(principal_components[:, 0], principal_components[:, 1], principal_components[:, 2],
                     c=dataset['Cluster'], cmap='viridis', alpha=0.6)

# Etichette e titolo
ax.set_xlabel('Componente Principale 1')
ax.set_ylabel('Componente Principale 2')
ax.set_zlabel('Componente Principale 3')
ax.set_title('Visualizzazione dei Cluster (PCA 3D)')

# Barra dei colori
cbar = plt.colorbar(scatter)
cbar.set_label('Cluster')

# Mostra il grafico
plt.show()

"""### üìå **Visualizzazione dei Giocatori per Cluster**

Il codice seguente visualizza i giocatori in ciascun cluster, mostrando alcune delle loro statistiche pi√π rilevanti. Ecco come funziona:

1. **Iterazione sui Cluster:**  
   Il ciclo `for cluster_id in range(optimal_k)` scorre ogni cluster creato dal modello di clustering. `optimal_k` √® il numero di cluster scelto in precedenza (in questo caso 6).

2. **Selezione dei Giocatori nel Cluster:**  
   Per ogni cluster, viene selezionato il sottoinsieme del dataset contenente i giocatori appartenenti a quel cluster. Questo viene fatto utilizzando la condizione `dataset['Cluster'] == cluster_id`.

3. **Visualizzazione dei Dati per Cluster:**  
   Una volta selezionato il sottoinsieme di giocatori, il codice visualizza un subset di colonne contenenti statistiche come il `gamertag`, il `wlRatio`, il `gamesPlayed` e altre informazioni importanti.
"""

for cluster_id in range(optimal_k):  # 'optimal_k' √® il numero di cluster
    cluster_players = dataset[dataset['Cluster'] == cluster_id]  # Seleziona i giocatori nel cluster
    print(f"Cluster {cluster_id}:")
    display(cluster_players[['gamertag', 'wlRatio', 'gamesPlayed', 'kdRatio', 'killstreak', 'totalLevelAccount', 'precisionHead', 'precisionAim', 'timePlayed']])  # Personalizza le colonne

"""### üìå **Descrizione dei Giocatori nel Dataset**

Nel nostro dataset, abbiamo rappresentato vari tipi di giocatori con diverse abilit√† e comportamenti nel gioco. Ecco una panoramica dei giocatori:
"""

player_debutante = {
    'gamertag': 'NoobPlayer01',
    'wlRatio': 2,
    'gamesPlayed': 2,
    'kdRatio': 0.6,
    'killstreak': 0,
    'totalLevelAccount': 1,
    'precisionHead': 0.1,
    'precisionAim': 0.05,
    'timePlayed': 1
}

player_2 = {
    'gamertag': 'ProGamerX',
    'wlRatio': 2.0,
    'gamesPlayed': 500,
    'kdRatio': 1.8,
    'killstreak': 20,
    'totalLevelAccount': 150,
    'precisionHead': 0.65,
    'precisionAim': 0.70,
    'timePlayed': 100
}

player_3 = {
    'gamertag': 'AverageJoe',
    'wlRatio': 1.2,
    'gamesPlayed': 200,
    'kdRatio': 1.0,
    'killstreak': 10,
    'totalLevelAccount': 50,
    'precisionHead': 0.40,
    'precisionAim': 0.50,
    'timePlayed': 50
}

player_4 = {
    'gamertag': 'WeekendWarrior',
    'wlRatio': 70.0,
    'gamesPlayed': 900,
    'kdRatio': 1.25,
    'killstreak': 20,
    'totalLevelAccount': 850,
    'precisionHead': 0.15,
    'precisionAim': 0.22,
    'timePlayed': 2500
}

player_5 = {
    'gamertag': 'SonoAbbastanzaForte67',
    'wlRatio': 22.0,
    'gamesPlayed': 215,
    'kdRatio': 0.71,
    'killstreak': 11,
    'totalLevelAccount': 642,
    'precisionHead': 0.04,
    'precisionAim': 0.14,
    'timePlayed': 379
}


player_6 = {
    'gamertag': 'MasterDestroyer89',
    'wlRatio': 3,
    'gamesPlayed': 1000,
    'kdRatio': 2.5,
    'killstreak': 30,
    'totalLevelAccount': 400,
    'precisionHead': 0.80,
    'precisionAim': 0.85,
    'timePlayed': 200
}

player_veterano = {
    'gamertag': 'NovaDestroyer42',
    'wlRatio': 25.0,
    'gamesPlayed': 250,
    'kdRatio': 1.35,
    'killstreak': 10,
    'totalLevelAccount': 800,
    'precisionHead': 0.85,
    'precisionAim': 0.60,
    'timePlayed': 1200
}

"""## Creazione di nuovi giocatori e predizione dei cluster

### 1. **Creazione del DataFrame con i nuovi giocatori**
Abbiamo definito un gruppo di nuovi giocatori con diverse caratteristiche, come il `gamertag`, `wlRatio`, `kdRatio`, `killstreak`, `totalLevelAccount`, `precisionHead`, `precisionAim`, e `timePlayed`.

### 2. **Rimozione della colonna `gamertag`**
Poich√© la colonna `gamertag` non √® utile per il clustering (essendo una stringa), √® stata rimossa dal DataFrame prima di procedere con la normalizzazione.

### 3. **Normalizzazione delle caratteristiche**
Le caratteristiche numeriche dei nuovi giocatori sono state normalizzate utilizzando lo stesso scaler applicato ai dati originali. Questo √® importante per garantire che le variabili siano su scala comparabile.

### 4. **Predizione dei cluster**
Utilizzando il modello `kmeans` precedentemente addestrato, abbiamo predetto i cluster a cui appartengono i nuovi giocatori.

### 5. **Assegnazione dei cluster**
Le etichette dei cluster previste sono state aggiunte al DataFrame dei nuovi giocatori come una nuova colonna denominata `Predicted Cluster`.

### 6. **Visualizzazione dei risultati**
Infine, abbiamo stampato i `gamertag` dei nuovi giocatori insieme ai cluster a cui sono stati assegnati, consentendo di osservare a quale gruppo di giocatori appartengono in base alle loro caratteristiche.
"""

# Creiamo un DataFrame con i nuovi giocatori
new_players = pd.DataFrame([player_debutante, player_2, player_3, player_4, player_5, player_6, player_veterano])

# Rimuoviamo il 'gamertag' dal DataFrame prima di normalizzarlo
new_players_features = new_players.drop(columns=['gamertag'])

# Normalizziamo le caratteristiche dei nuovi giocatori
new_players_scaled = scaler.transform(new_players_features)

# Predizione del cluster per ciascun nuovo giocatore
predicted_clusters = kmeans.predict(new_players_scaled)

# Assegniamo i cluster ai nuovi giocatori
new_players['Predicted Cluster'] = predicted_clusters

# Visualizziamo il risultato con il gamertag mantenuto
print(new_players[['gamertag', 'Predicted Cluster']])

"""# Creazione delle Lobby con KNN

In questo processo, stiamo creando delle lobby per i nuovi giocatori basandoci sul loro cluster assegnato tramite **KMeans** e selezionando i giocatori pi√π simili utilizzando l'algoritmo **K-Nearest Neighbors (KNN)**. Ecco una panoramica delle fasi principali:

#### 1. Assegnazione del Cluster
Ogni nuovo giocatore √® stato precedentemente assegnato a un cluster tramite il modello **KMeans**. Il cluster a cui appartiene ciascun giocatore √® identificato tramite la colonna `Predicted Cluster`.

#### 2. Selezione dei Giocatori del Cluster
Una volta identificato il cluster di un giocatore, selezioniamo tutti gli altri giocatori appartenenti allo stesso cluster dal nostro dataset. Questo passaggio assicura che i giocatori siano raggruppati in base a caratteristiche simili.

#### 3. Normalizzazione dei Dati
Poich√© le caratteristiche dei giocatori sono su scale diverse, utilizziamo un **scaler** (probabilmente un `StandardScaler` o simile) per normalizzare i dati. In questo modo, tutte le caratteristiche sono portate sulla stessa scala, prevenendo distorsioni nel calcolo delle distanze.

#### 4. Applicazione del KNN
Per selezionare i giocatori pi√π simili, utilizziamo l'algoritmo **K-Nearest Neighbors (KNN)**. KNN √® un algoritmo di apprendimento non supervisionato che cerca i punti pi√π vicini a un punto dato (in questo caso, il nuovo giocatore).

- **Numero di vicini (n_neighbors)**: Definiamo il numero di giocatori da considerare come vicini, impostato a un massimo di 11. Questo significa che per ogni giocatore, il sistema cercher√† i 11 giocatori pi√π vicini nel cluster.

- **Calcolo delle distanze**: KNN calcola le distanze tra il giocatore in esame e gli altri giocatori del suo cluster, selezionando quelli pi√π simili.

#### 5. Formazione della Lobby
Una volta selezionati i giocatori pi√π vicini, la lobby viene creata con il nuovo giocatore aggiunto in cima alla lista. I giocatori selezionati tramite KNN completano la lobby, creando cos√¨ un gruppo di giocatori con caratteristiche simili.

#### 6. Visualizzazione della Lobby
Infine, per ogni giocatore, viene creata una lobby e vengono stampati i dettagli del giocatore principale (il nuovo giocatore) e degli altri membri della lobby. La tabella mostra le caratteristiche principali come `gamertag`, `wlRatio`, `gamesPlayed`, `kdRatio`, ecc., per ogni giocatore nella lobby.

### Vantaggi dell'uso del KNN:
- **Personalizzazione delle lobby**: Ogni giocatore viene accoppiato con altri giocatori simili, migliorando l'esperienza di gioco.
- **Semplicit√† e efficienza**: KNN √® relativamente facile da implementare e non richiede una fase di addestramento complessa.
- **Flessibilit√†**: KNN pu√≤ essere adattato facilmente per variare il numero di vicini o le caratteristiche da considerare nel matchmaking.

In sintesi, **KNN** √® utilizzato per creare delle lobby che raccolgono giocatori simili in base alle loro performance e abitudini di gioco, garantendo sessioni di gioco equilibrate e divertenti.

"""

import warnings
warnings.filterwarnings("ignore", category=UserWarning)

# Creiamo le lobby per i due nuovi giocatori
lobbies = {}
features = ['wlRatio', 'gamesPlayed', 'kdRatio', 'killstreak',
            'totalLevelAccount', 'precisionHead', 'precisionAim', 'timePlayed']

for i, player in new_players.iterrows():
    cluster_id = player['Predicted Cluster']  # Cluster assegnato tramite KMeans
    player_data = player[features].values.reshape(1, -1)  # Caratteristiche numeriche per il calcolo

    # Selezioniamo tutti i giocatori che appartengono al cluster del giocatore corrente
    cluster_players = dataset[dataset['Cluster'] == cluster_id]

    # Rimuoviamo il giocatore principale dalla selezione
    cluster_players = cluster_players[cluster_players['gamertag'] != player['gamertag']]

    if cluster_players.empty:
        print(f"Cluster {cluster_id} vuoto o gi√† processato, salto il giocatore {player['gamertag']}")
        continue

    # Normalizziamo i dati del giocatore e dei giocatori del cluster
    player_data_scaled = scaler.transform(player_data)
    cluster_players_scaled = scaler.transform(cluster_players[features])

    # Adattiamo il numero di vicini in base ai giocatori disponibili
    n_neighbors = min(len(cluster_players), 11)  # Max 11 vicini da aggiungere
    knn = NearestNeighbors(n_neighbors=n_neighbors)
    knn.fit(cluster_players_scaled)
    distances, indices = knn.kneighbors(player_data_scaled)

    # Selezioniamo i giocatori pi√π vicini
    lobby_players = cluster_players.iloc[indices[0]].copy()

    # Aggiungiamo il nuovo giocatore in cima alla lista
    lobby_players = pd.concat([pd.DataFrame(player).T, lobby_players])

    # Salviamo la lobby per questo giocatore
    lobbies[f'Lobby_Player_{i}'] = lobby_players

# Stampiamo le lobby per ogni giocatore
for i, (lobby_name, lobby) in enumerate(lobbies.items(), start=1):
    print(f"\n===== {lobby_name} =====")

    # Otteniamo il giocatore principale
    main_player = lobby.iloc[0][['gamertag'] + features]

    # Stampa il giocatore principale con tabulate
    print("Giocatore principale:")
    print(tabulate([main_player.values], headers=['Gamertag'] + features, tablefmt='grid'))

    # Stampiamo gli altri membri della lobby
    other_players = lobby.iloc[1:][['gamertag'] + features]
    print("\nAltri giocatori nella lobby:")
    print(tabulate(other_players.values, headers=['Gamertag'] + features, tablefmt='grid'))

import warnings
warnings.filterwarnings("ignore", category=UserWarning)


def plot_all_clusters():
    unique_clusters = dataset['Cluster'].unique()

    for cluster_n in unique_clusters:
        cluster_players = dataset[dataset['Cluster'] == cluster_n]
        if cluster_players.empty:
            continue

        # Applichiamo PCA per ridurre a 2D
        pca = PCA(n_components=2)
        reduced_data = pca.fit_transform(scaler.transform(cluster_players[features]))

        plt.figure(figsize=(8, 6))
        plt.scatter(reduced_data[:, 0], reduced_data[:, 1], c='blue', label=f'Cluster {cluster_n}')

        # Etichette con i gamertag
        for i, txt in enumerate(cluster_players['gamertag']):
            plt.annotate(txt, (reduced_data[i, 0], reduced_data[i, 1]), fontsize=8, alpha=0.7)

        plt.xlabel("PCA Component 1")
        plt.ylabel("PCA Component 2")
        plt.title(f"Visualizzazione dei giocatori nel Cluster {cluster_n}")
        plt.legend()
        plt.show()
plot_all_clusters()

# Funzione per salvare la tabella come immagine
def save_table_as_image(df, filename='table_image.png'):
    fig, ax = plt.subplots(figsize=(8, 4))  # Impostiamo la dimensione della figura
    ax.axis('tight')  # Disabilita gli assi
    ax.axis('off')  # Disabilita gli assi

    # Crea la tabella
    tab = table(ax, df, loc='center', colWidths=[0.2]*len(df.columns))

    # Personalizza la tabella
    tab.auto_set_font_size(False)  # Disabilita il ridimensionamento automatico del font
    tab.set_fontsize(10)  # Impostiamo la dimensione del font
    tab.scale(1.2, 1.2)  # Aumentiamo la scala della tabella per renderla pi√π visibile

    # Salva l'immagine
    plt.savefig(filename, bbox_inches='tight', pad_inches=0.1)
    plt.close()  # Chiudiamo la figura per evitare che venga visualizzata due volte

# Iteriamo su tutte le lobby e salviamo ogni tabella come immagine
for i, (lobby_name, lobby) in enumerate(lobbies.items(), start=1):
    lobby_data = lobby[['gamertag'] + features]
    filename = f'lobby_{i}_table.png'  # Definiamo il nome del file per ogni lobby
    save_table_as_image(lobby_data, filename)  # Salviamo l'immagine della lobby

    # Mostriamo l'immagine nel notebook
    display(Image(filename=filename))

"""# Creazione delle Squadre per i Giocatori

In questo sistema, i giocatori all'interno di una lobby vengono separati in squadre da due, seguendo una distribuzione casuale. La funzione che gestisce questo processo √® la `crea_squadre`, che divide i giocatori in due squadre, alternandoli in modo equo.

## Funzione `crea_squadre`

La funzione `crea_squadre` riceve due input:
- **`lobby`**: La lista di giocatori nella lobby.
- **`input_player`**: Il giocatore specifico da evidenziare (per esempio, il giocatore di input).

### Passaggi della Funzione:
1. **Selezione dei Giocatori**:
   - I giocatori vengono estratti dalle colonne delle caratteristiche numeriche (definite in `features`).
   - Successivamente, i giocatori vengono mescolati casualmente con `random.shuffle(players)` per evitare qualsiasi bias nella distribuzione.

2. **Creazione delle Squadre**:
   - Si creano due squadre vuote, `Rogue Black Ops` e `Crimson One`, all'interno di un dizionario.
   - I giocatori vengono assegnati alternativamente a ciascuna squadra, con il controllo che ogni squadra abbia lo stesso numero di giocatori.

3. **Evidenziazione del Giocatore di Input**:
   - Ogni volta che il giocatore di input (passato alla funzione) viene aggiunto alla lista, viene evidenziato con un asterisco (`*`), in modo da renderlo facilmente distinguibile.

4. **Stampa dei Risultati**:
   - La funzione stampa il nome di ciascuna squadra insieme ai membri, evidenziando il giocatore di input.
"""

# Funzione per separare i giocatori in squadre da 2
def crea_squadre(lobby, input_player):
    # Creiamo una lista di giocatori nella lobby
    players = lobby[features].values.tolist()

    # Mescoliamo i giocatori in modo casuale
    random.shuffle(players)

    # Creiamo le squadre
    squadre = {
        "Rogue Black Ops": [],
        "Crimson One": []
    }

    # Aggiungiamo i giocatori alle squadre
    for i in range(0, len(players), 2):
        # Alterniamo tra le due squadre
        squadra = "Rogue Black Ops" if i % 4 == 0 else "Crimson One"
        squadre[squadra].append(players[i:i+2])

    # Stampa delle squadre
    for squad_name, members in squadre.items():
        print(f"\n{squad_name}\n")
        for pair in members:
            for player in pair:
                # Troviamo il gamertag corrispondente
                gamertag = lobby.loc[lobby[features].apply(tuple, axis=1) == tuple(player), 'gamertag'].values[0]
                # Verifica se il giocatore √® quello di input
                if player == input_player:
                    print(f"*{gamertag}* (Giocatore input)")  # Evidenziato
                else:
                    print(gamertag)  # Player normale

# Esempio: Per ogni lobby separa i giocatori in squadre
for i, (lobby_name, lobby) in enumerate(lobbies.items(), start=1):
    print(f"\n===== Lobby {i} =====")

    # Supponiamo che il primo giocatore della lobby sia quello di input
    input_player = lobby.iloc[0][features].values.tolist()  # O prendi il tuo giocatore specifico

    # Crea le squadre e stampa
    crea_squadre(lobby, input_player)

"""#**Dopo la fase di modeling, abbiamo l'evaluation.**

##**ORA STUDIAMO LE LOBBY**.
## Evaluation della Coerenza dei Cluster

L'evaluation nel contesto del clustering serve a misurare la coesione dei gruppi creati. Un buon clustering raggruppa i giocatori con skill simili, migliorando il bilanciamento delle partite.

### **Calcolo della Coesione dei Cluster**
1. **Calcolo della varianza interna al cluster**  
   - Si misura la deviazione standard media delle skill all'interno di ogni cluster.
  
2. **Normalizzazione della coesione**  
   - Si usa una scala percentuale inversa: minore √® la varianza, maggiore √® la coesione.  
   - Il valore di coesione (`giocabilit√†_percent`) √® calcolato come:  
     \[
     100 - \left(\frac{\text{deviazione standard media del cluster}}{\text{deviazione standard massima del dataset}}\right) \times 100
     \]
  
3. **Visualizzazione grafica**  
   - Un grafico a barre mostra la coerenza di ciascun cluster.  
   - Una soglia (`40%`) viene indicata per evidenziare cluster con scarsa coesione.

"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

# Definiamo le feature chiave per valutare la skill
skill_features = ['wlRatio', 'kdRatio', 'precisionAim', 'totalLevelAccount', 'timePlayed']

# Creiamo un dizionario per salvare i risultati
cluster_coherence = {}

# Calcoliamo la varianza media per ogni cluster
for cluster_id in range(optimal_k):
    cluster_players = dataset[dataset['Cluster'] == cluster_id][skill_features]

    if cluster_players.empty:
        print(f"‚ö†Ô∏è Cluster {cluster_id} √® vuoto, salto il calcolo.")
        continue

    # Calcoliamo la deviazione standard media tra i giocatori del cluster
    cluster_std = cluster_players.std().mean()

    # Normalizziamo la giocabilit√†: minore √® la varianza, maggiore √® la coesione
    # Usiamo una scala percentuale inversa (pi√π bassa la std, pi√π alta la percentuale di giocabilit√†)
    max_std = dataset[skill_features].std().mean()
    giocabilita_percent = max(0, 100 - (cluster_std / max_std) * 100)

    cluster_coherence[cluster_id] = giocabilita_percent

# Stampa i risultati
print("\n===== Giocabilit√† nei Cluster =====")
for cluster_id, giocabilita in cluster_coherence.items():
    print(f"üéØ Cluster {cluster_id}: {giocabilita:.2f}% coerenza di skill")

# Creiamo un grafico a barre per visualizzare la giocabilit√† nei cluster
plt.figure(figsize=(8,5))
plt.bar(cluster_coherence.keys(), cluster_coherence.values(), color='royalblue')
plt.axhline(y=40, color='r', linestyle='--', label="Soglia sbilanciamento")
plt.xlabel("Cluster")
plt.ylabel("Giocabilit√† (%)")
plt.title("Distribuzione della Giocabilit√† per Cluster")
plt.ylim(0, 100)
plt.xticks(range(optimal_k))
plt.show()

"""# Fairness e Evaluation nel Matchmaking

## Fairness nel Matchmaking

La fairness in un sistema di matchmaking si riferisce alla capacit√† di creare partite equilibrate, dove le squadre abbiano skill simili per garantire un'esperienza di gioco competitiva e divertente.  

### **Calcolo della Fairness**
Il codice divide i giocatori in due squadre casuali e calcola la fairness basandosi sulla media delle loro skill:

1. **Calcolo della skill media**  
   - Si prendono le feature chiave e si calcola la media per ciascuna squadra.
  
2. **Determinazione dello sbilanciamento**  
   - Si calcola il rapporto tra la squadra pi√π forte e quella pi√π debole.  
   - Se il valore √® superiore a `1.4`, la partita viene considerata potenzialmente sbilanciata.

3. **Visualizzazione grafica**  
   - Si genera un grafico per mostrare il livello di fairness di ogni partita.  
   - Le partite con fairness score superiore a `1.4` vengono evidenziate in rosso.
"""

import random

# Funzione per calcolare la fairness di una partita
def calcola_fairness(team1, team2):
    # Calcoliamo la media skill per team (usando le stesse feature di skill)
    team1_skill = team1[skill_features].mean().mean()
    team2_skill = team2[skill_features].mean().mean()

    # Calcoliamo il fairness score (rapporto tra il team pi√π forte e quello pi√π debole)
    fairness_score = max(team1_skill, team2_skill) / min(team1_skill, team2_skill)

    return fairness_score

# Funzione per generare le squadre e calcolare la fairness per ogni partita
def valuta_partite(lobbies):
    fairness_scores = []

    for i, (lobby_name, lobby) in enumerate(lobbies.items(), start=1):
        print(f"\n===== Valutazione Fairness - {lobby_name} =====")

        # Mischiamo casualmente i giocatori e dividiamoli in due squadre
        shuffled_players = lobby.sample(frac=1).reset_index(drop=True)
        met√† = len(shuffled_players) // 2
        team1 = shuffled_players.iloc[:met√†]
        team2 = shuffled_players.iloc[met√†:]

        # Calcoliamo la fairness della partita
        fairness_score = calcola_fairness(team1, team2)
        fairness_scores.append(fairness_score)

        # Stampiamo il risultato
        print(f"üîπ Fairness Score: {fairness_score:.2f} (Vicino a 1.4 √® meglio)")
        if fairness_score > 1.4:
            print("‚ö†Ô∏è Attenzione: Partita potenzialmente sbilanciata!")

    # Grafico della fairness di tutte le partite
    plt.figure(figsize=(8,5))
    plt.bar(range(len(fairness_scores)), fairness_scores, color=['green' if x <= 1.4 else 'red' for x in fairness_scores])
    plt.axhline(y=1.4, color='r', linestyle='--', label="Soglia sbilanciamento")
    plt.xlabel("Partita")
    plt.ylabel("Fairness Score")
    plt.title("Distribuzione della Fairness delle Partite")
    plt.legend()
    plt.show()

# Eseguiamo la valutazione
valuta_partite(lobbies)

"""## **Conclusione**
- Un matchmaking efficace si basa su **cluster coerenti** e **partite equilibrate al punto giusto**.  
- Un **fairness score vicino a 1.4** garantisce partite pi√π competitive.  
- La **coesione dei cluster** aiuta a formare lobby con giocatori simili, migliorando la qualit√† del matchmaking.  
"""

#dataset.to_csv('/content/modified_dataset.csv', index=False)

#from google.colab import files
#files.download('/content/modified_dataset.csv')